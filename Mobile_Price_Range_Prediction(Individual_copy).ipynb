{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirtha2016/Ml-Classification-_Mobile_Price_Range_Prediction/blob/main/Mobile_Price_Range_Prediction(Individual_copy).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - ***MOBILE PRICE RANGE PREDICTION :-***"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** - ***TIRTHA BOSE***"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mobile phone industry is fiercely competitive, and the price of a mobile phone is determined by multiple factors such as battery power, Bluetooth, camera quality, and screen size. To investigate the factors that influence the price range of mobile phones, a study was conducted. The study utilized a dataset containing approximately 21 variables to forecast the price range of mobile phones, which are categorized as low, medium, high, and very high.\n",
        "\n",
        " Initially, the analysis process focused on data wrangling, which involved managing missing values and verifying unique values. During this stage, it was discovered that 180 mobile phones had a pixel resolution height of 0, and two phones had a screen width of 0 cm. It is not logical for a phone screen width or pixel height to be 0, so the I decided to replace these 0 values with the mean values. This ensured that the dataset had no missing values.\n",
        "\n",
        " After I finished data wrangling, I performed exploratory data analysis (EDA). From this analysis, I discovered that all categories of mobile phones had an equal price range distribution. Furthermore, I found that there was a positive correlation between the battery capacity of a phone and its price range. The distribution of battery capacity also gradually increased as the price range increased, implying that consumers may be willing to pay more for a mobile phone with a higher battery capacity. In terms of Bluetooth usage, I found that almost half of the devices had it, while the other half did not.\n",
        "\n",
        " From the scatter plot, it was evident that there was a positive correlation between RAM and price range. The majority of the data points were clustered towards the upper right corner, indicating that as the price range increased, so did the amount of RAM in the device. The study also discovered that the count of devices with dual sim was increasing for the highest price range. Furthermore, the distribution of primary camera megapixels across various target categories remained consistent, suggesting that this feature may not have a significant impact on the price range of mobile phones.\n",
        "\n",
        " Based on the analysis of screen size distribution among different target categories, it was observed that there was not a significant difference in the distribution. This suggests that screen size alone may not be the primary factor in determining target categories. However, this consistency in distribution can be beneficial for predictive modeling, as it indicates that screen size may not play a significant role in distinguishing between different target categories, enabling other features to have a more significant impact in determining the target categories. Additionally, the study revealed that mobile phones with higher price ranges were generally lighter in weight than those with lower price ranges.\n",
        "\n",
        " Following the exploratory data analysis (EDA), the study conducted hypothesis testing on three statements while handling outliers. During this process, the study identified that RAM, battery power, and pixel quality were the most significant factors influencing the price range of mobile phones. Afterward, the study engaged in feature engineering and utilized various machine learning models, such as\n",
        "\n",
        " 1) Logistic regression,\n",
        "\n",
        " 2) Random forest, and\n",
        "\n",
        " 3) XGBoost.\n",
        "\n",
        " After conducting experiments, the study found that logistic regression and XGBoost algorithms with hyperparameter tuning delivered the most accurate results in predicting the price range of mobile phones.\n",
        "\n",
        "In summary, the study discovered that the mobile phones in the dataset were separated into four distinct price ranges, each containing an equivalent number of elements. Roughly half of the devices in the dataset had Bluetooth, while the other half did not. Additionally, the study observed that as the price range increased, there was a gradual rise in battery power, and the amount of RAM in the device exhibited continuous growth from low-cost to very high-cost phones. Moreover, the study identified that expensive phones generally tended to be lighter than their lower-priced counterparts."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/tirtha2016/Ml-Classification-_Mobile_Price_Range_Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the competitive mobile phone market, companies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phone(eg:- RAM, Internal Memory, etc) and its selling price. In this problem, we do not have to predict the actual price but a price range indicating how high the price is.**\n",
        "\n",
        "Data Overview\n",
        "\n",
        "* Battery_power - Total energy a battery can store in one time measured in mAh\n",
        "\n",
        "* Blue - Has bluetooth or not\n",
        "\n",
        "* *Clock_speed* - speed at which microprocessor executes instructions\n",
        "\n",
        "* *Dual_sim* - Has dual sim support or not\n",
        "\n",
        "* *Fc* - Front Camera mega pixels\n",
        "\n",
        "* *Four_g* - Has 4G or not\n",
        "\n",
        "* *Int_memory* - Internal Memory in Gigabytes\n",
        "\n",
        "* *M_dep* - Mobile Depth in cm\n",
        "\n",
        "* *Mobile_wt* - Weight of mobile phone\n",
        "\n",
        "* *N_cores* - Number of cores of processor\n",
        "\n",
        "* *Pc* - Primary Camera mega pixels\n",
        "\n",
        "* *Px_height* - Pixel Resolution Height\n",
        "\n",
        "* *Px_width* - Pixel Resolution Width\n",
        "\n",
        "* *Ram* - Random Access Memory in Mega Bytes\n",
        "\n",
        "* *Sc_h* - Screen Height of mobile in cm\n",
        "\n",
        "* *Sc_w* - Screen Width of mobile in cm\n",
        "\n",
        "* *Talk_time* - longest time that a single battery charge will last when you are\n",
        "\n",
        "* *Three_g* - Has 3G or not\n",
        "\n",
        "* *Touch_screen* - Has touch screen or not\n",
        "\n",
        "* *Wifi* - Has wifi or not\n",
        "\n",
        "* *Price_range* - This is the target variable with value of\n",
        "\n",
        " 0(low cost),\n",
        "\n",
        " 1(medium cost),\n",
        "\n",
        " 2(high cost) and\n",
        "\n",
        " 3(very high cost).\n",
        "\n",
        "* Thus our target variable has 4 categories so basically it is a Multiclass classification problem.\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Mounting Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Mobile Price Range Dataset\n",
        "mp_df = pd.read_csv('/content/drive/MyDrive/ML PROJECT/Ml  Classification Project/data_mobile_price_range.csv')"
      ],
      "metadata": {
        "id": "B3fmXbcvagY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# first 7 rows  of the dataset\n",
        "# Checking the first 5 rows of data\n",
        "mp_df.head(7)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seven rows of the dataset from the bottom\n",
        "mp_df.tail(7)"
      ],
      "metadata": {
        "id": "d15TA6Kzbcf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "mp_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "mp_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_values_count = len(mp_df[mp_df.duplicated()])\n",
        "\n",
        "print(\"Number of duplicate values:\", duplicate_values_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(mp_df,\n",
        "         fontsize=10,\n",
        "         figsize=(7,4),\n",
        "         color='magenta')\n",
        "plt.title('Missing values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above analysis we got to know the following things about our dataset till now**\n",
        "\n",
        "*   Our dataset consist of 2000 rows and 21 columns.\n",
        "\n",
        "*  It has no null or empty values in the dataset\n",
        "\n",
        "*  It has no duplicate values also\n",
        "\n",
        "*  It consist two datatypes float and integers"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "mp_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the columns\n",
        "print(f'There are {len(mp_df.columns)} columns in this mobile price range dataset')"
      ],
      "metadata": {
        "id": "FOwXqFifznOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Checking statistical data on numerical columns\n",
        "mp_df.describe(include='all')\n",
        "\n",
        "# Transpose of Data Description for better visibility and analysis\n",
        "mp_df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Battery_power: Total energy a battery can store in single time measured in mAh.\n",
        "\n",
        "2) Blue: Has bluetooth or not.\n",
        "\n",
        "3) Clock_speed: Speed at which microprocessor executes instructions.\n",
        "\n",
        "4) Dual_sim: Has dual sim support or not.\n",
        "\n",
        "5) Fc: Front Camera Mega Pixels.\n",
        "\n",
        "6) Four_g: Has 4G or not.\n",
        "\n",
        "7) Int_memory: Internal Memory in Gigabytes.\n",
        "\n",
        "8) M_dep: Mobile Depth in cm.\n",
        "\n",
        "9) Mobile_wt: Weight of mobile phone.\n",
        "\n",
        "10) N_cores: Number of cores of processor.\n",
        "\n",
        "11) Pc: Primary Camera Mega Pixels.\n",
        "\n",
        "12) Px_height: Pixel Resolution Height.\n",
        "\n",
        "13) Px_width: Pixel Resolution Width.\n",
        "\n",
        "14) Ram: Random Access Memory in Megabytes.\n",
        "\n",
        "15) Touch_screen: Has touch screen or not.\n",
        "\n",
        "16) Wifi: Has wifi or not.\n",
        "\n",
        "17) Sc_h: Screen Height of mobile in cm.\n",
        "\n",
        "18) Sc_w: Screen Width of mobile in cm.\n",
        "\n",
        "19) Talk_time: longest time that a single battery charge will last when you are online.\n",
        "\n",
        "20) Three_g: Has 3G or not.\n",
        "\n",
        "21) Wifi: Has wifi or not.\n",
        "\n",
        "22) Price_range: This is the target variable with value of 0(low cost), 1(medium cost), 2(High Cost), 3(Very High cost)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in mp_df.columns:\n",
        "    unique_values = mp_df[column].unique()\n",
        "    print(f\"The Unique values for variable [{column}] are: {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the total number of Unique Values for each variable\n",
        "mp_df.nunique()"
      ],
      "metadata": {
        "id": "Bd7KWvae2RIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# It is not logical for a phone screen width or pixel height to have a value of 0, so we need to make sure to verify and address such instances to prevent any complications in our analysis\n",
        "# Count of phones with sc_w = 0\n",
        "sc_w_zero_count = sum(mp_df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {sc_w_zero_count}\")\n",
        "\n",
        "# Count of phones with px_height = 0\n",
        "px_height_zero_count = sum(mp_df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing 0 values with the mean value\n",
        "sc_w_mean = mp_df.sc_w.mean()\n",
        "px_height_mean = mp_df.px_height.mean()\n",
        "\n",
        "mp_df.sc_w = np.where(mp_df.sc_w == 0, sc_w_mean, mp_df.sc_w)\n",
        "mp_df.px_height = np.where(mp_df.px_height == 0, px_height_mean, mp_df.px_height)\n",
        "\n",
        "# Printing the updated dataframe\n",
        "print(mp_df)"
      ],
      "metadata": {
        "id": "ONBasLLW34dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for the 0 values in the sc_w and px_height columns after the data wrangling\n",
        "\n",
        "# Count of phones with sc_w = 0\n",
        "sc_w_zero_count = sum(mp_df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {sc_w_zero_count}\")\n",
        "\n",
        "# Count of phones with px_height = 0\n",
        "px_height_zero_count = sum(mp_df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")"
      ],
      "metadata": {
        "id": "53mpF5In4cxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Duplicate Values"
      ],
      "metadata": {
        "id": "6tuLYgsW4xbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether there are duplicates or not\n",
        "print(f'There are {len(mp_df[mp_df.duplicated()])} duplicate values in the mobile price range data set')"
      ],
      "metadata": {
        "id": "mDTOpXZe4071"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Missing Values/Null Values"
      ],
      "metadata": {
        "id": "YoiuLAmS5D6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "j7z-fx_n4_WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We observed the following insights:\n",
        "\n",
        "i) I discovered that there are 2 phones in the dataset with a pixel height value of 0, and 180 phones with a screen width value of 0.\n",
        "\n",
        "\n",
        "ii) It is illogical for a phone screen width or pixel height to have a value of 0, so it is necessary to identify and address these instances properly to prevent any potential problems in our analysis.\n",
        "\n",
        "\n",
        "iii) The 0 values in the dataset have been replaced with their respective column mean values, ensuring that there are no longer any missing values in the table. Therefore, our data is now prepared for data analysis."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**UNIVARIATE ANALYSIS:-**"
      ],
      "metadata": {
        "id": "5ZQhrfJQ6B_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is the distribution of battery power of different mobile phones?"
      ],
      "metadata": {
        "id": "NTtRdNZ76ZXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "6# Chart - 1 visualization code\n",
        "plt.figure(figsize = (7, 7))\n",
        "sns.displot(mp_df[\"battery_power\"], color='blue' , edgecolor='black',linewidth=1,\n",
        "            bins = 20)\n",
        "plt.xlabel('Battery Power')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Battery Power')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use this \"displot\" chart because it help us to represents the univariate distribution of data i.e. data distribution of a variable against the density distribution"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot illustrates the distribution of battery capacity in the dataset, measured in milliampere-hour (mAh). It can be observed that the distribution of battery capacity is almost uniform, with a slightly higher frequency in the lower battery power range. This implies that lower-end phones are sold more frequently than higher-end ones."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the graph indicates that there is a slight skew towards lower end phones in terms of frequency. This suggests that lower end phone models are produced more frequently. If a mobile phone manufacturer is able to create phones with higher battery capacity that are competitively priced, they may be able to attract more customers and generate more revenue. This information could also be used to guide marketing and advertising strategies, as companies can focus on promoting the battery capacity of their phones as a key selling point to potential customers."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is the percentage of different classes of mobile price range?"
      ],
      "metadata": {
        "id": "nxdRpLmkE6JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Classes of Mobile Price Range\n",
        "price_counts = mp_df['price_range'].value_counts()\n",
        "plt.pie(price_counts, labels = price_counts.index, autopct='%1.1f%%', shadow=True, startangle=180, explode=(0.05,0.05,0.05,0.05),\n",
        "       wedgeprops={\"edgecolor\":\"0\",'linewidth': 1,'linestyle': 'solid', 'antialiased': True})\n",
        "plt.title('Price Range Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used this \"pie charts\" because it is  used to show percentages of a whole, and represents percentages at a set point in time. Unlike bar graphs and line graphs, pie charts do not show changes over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different categories of price range of phones have equal percentage of distribution in the data set."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above found insights, we can assume that every category of phone are equally distributed, perhaps the demand for them are equal."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If bluetooth available or not???"
      ],
      "metadata": {
        "id": "Sz3qQhUdhsdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig = plt.figure(1, figsize=(8,8))\n",
        "blue_data = [(len(mp_df[mp_df.blue==0])),(len(mp_df[mp_df.blue==1]))]\n",
        "blue_keys=[\"Bluetooth_Avilable\",\"Bluetooth_Not_Avilable\"]\n",
        "explode = [0, 0.1]\n",
        "palette_color =sns.color_palette('rocket_r')\n",
        "plt.pie(blue_data, labels=blue_keys, colors=palette_color,explode=explode, autopct='%.0f%%',textprops={'fontsize': 12})\n",
        "plt.title('Bluetooth Avilable OR Not Avilable')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used pie chart here because it help us to check the bluetooth connectivity in phones with percentage accuracy\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can see half the devices have Bluetooth, and half donâ€™t."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Bluetooth features distribution is almost similar along all the price ranges variable, it may not be helpful in making predictions."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4  BIVARIATE ANALYSIS"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3G And 4G Connectivity"
      ],
      "metadata": {
        "id": "gpxpuIzNjPc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "binary_features = [ 'four_g', 'three_g']\n",
        "for dataset in binary_features:\n",
        "  fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (8 ,8))\n",
        "\n",
        "  mp_df[dataset].value_counts().plot.pie (autopct='%1.1f%%', ax = ax1,colors=palette_color, shadow=True,labeldistance=None)\n",
        "  ax1.set_title('Distribution by price range')\n",
        "  ax1.legend(['Support', 'Does not Support'])\n",
        "  sns.countplot(x = dataset, hue = 'price_range', data = mp_df, ax = ax2, color = 'red')\n",
        "  ax2.set_title('Distribution by price range')\n",
        "  ax2.set_xlabel(dataset)\n",
        "  ax2.legend(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "  ax2.set_xticklabels(['Does not Support', 'Support'])\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i have used pie chart and bar graph to check the connectivity of 3G and 4G on mobiles"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of price range almost similar of supported and non supported feature in 4G . So that is not useful of prediction.\n",
        "Feature 'three_g' play an important feature in Price prediction."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.it will help us to create a postitive business impact."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Relationship between RAM and price range"
      ],
      "metadata": {
        "id": "hdT35hq1k6JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Defining the colors for each price range\n",
        "colors = ['cyan', 'magenta', 'yellow', 'black']\n",
        "\n",
        "# Creating a colormap using the colors\n",
        "cmap = mcolors.ListedColormap(colors)\n",
        "\n",
        "# Creating the scatter plot\n",
        "plt.scatter(mp_df['price_range'], mp_df['ram'], c = mp_df['price_range'], cmap = cmap)\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('RAM')\n",
        "plt.xticks([0, 1, 2, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot is commonly used to visualize the relationship between two continuous variables. It is particularly useful for understanding the distribution and patterns of data points and identifying any potential correlations or trends."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot reveals a noticeable positive correlation between RAM and price range, as most of the data points gather towards the upper right corner. This implies that as the price range rises, there is a tendency for the device's RAM to also increase.\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observations derived from the scatter plot, such as the positive correlation between RAM and price range, hold significance for businesses. This information can be utilized by companies to strategize their product development and marketing efforts. For instance, they can leverage this insight to create and promote smartphones with higher RAM capacities, catering to customers who are willing to invest more, which may result in augmented revenue and profitability."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Relationship between pixel width / pixel height and price range"
      ],
      "metadata": {
        "id": "p_EIb3V1lfEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Setting up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize = (15, 5))\n",
        "\n",
        "# Creating a kernel density estimate plot for the pixel width distribution for each price range\n",
        "sns.kdeplot(data = mp_df, x = 'px_width', hue = 'price_range', fill = True, common_norm = False, palette = 'coolwarm', ax = axs[0])\n",
        "axs[0].set_xlabel('Pixel Width')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Width Distribution by Price Range')\n",
        "\n",
        "# Creating a box plot of pixel width for each price range\n",
        "sns.boxplot(data = mp_df, x = 'price_range', y = 'px_width', palette = 'coolwarm', ax = axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Width')\n",
        "axs[1].set_title('Pixel Width by Price Range')\n",
        "\n",
        "# Adjusting the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plotting the graph\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pixel_height"
      ],
      "metadata": {
        "id": "qnqB_MM3pNKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize = (15, 5))\n",
        "\n",
        "# Creating a kernel density estimate plot for the pixel height distribution for each price range\n",
        "sns.kdeplot(data = mp_df, x = 'px_height', hue = 'price_range', fill = True, common_norm = False, palette = 'coolwarm', ax = axs[0])\n",
        "axs[0].set_xlabel('Pixel Height')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Height Distribution by Price Range')\n",
        "\n",
        "# Creating a box plot of pixel height for each price range\n",
        "sns.boxplot(data = mp_df, x = 'price_range', y = 'px_height', palette = 'coolwarm', ax = axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Height')\n",
        "axs[1].set_title('Pixel Height by Price Range')\n",
        "\n",
        "# Adjusting the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plotting the graph\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-ZSatJXSpUCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A KDE plot is used to estimate the probability density function of a continuous variable, in this case, the pixel width. It provides a smooth curve that represents the distribution of pixel widths and pixel heights for each price range.\n",
        "\n",
        "A box plot summarizes the distribution of a numerical variable, showcasing key statistics such as the median, quartiles, and any outliers present."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the pixel width distribution across different price ranges reveals that the relationship between pixel width and cost is not a linear progression. Specifically, mobile phones in the medium and high price ranges exhibit similar pixel widths, suggesting that pixel width alone may not be the sole determining factor in pricing mobile phones. Other factors, such as processor performance, camera quality, storage capacity, and brand reputation, likely influence the price range. Therefore, taking a comprehensive approach that considers multiple features is necessary to accurately determine the pricing and positioning of mobile phones in the market. Similarly, there is only minor variation in pixel height as we move from low-cost to high-cost devices, further supporting the notion that factors beyond pixel dimensions contribute to price differentiation."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of pixel height distribution across various price ranges offers valuable insights that can have a positive impact on businesses, particularly mobile phone manufacturers and marketers. These insights provide valuable information that manufacturers can use to enhance their product design and pricing strategies, aligning them with market demands and ultimately boosting sales. Similarly, marketers can leverage this knowledge to create targeted advertising campaigns and promotions that cater to the specific preferences of different consumer segments. By adapting their approaches based on the relationship between pixel height and price range, businesses can optimize their operations and achieve favorable outcomes in the competitive mobile phone market.\n",
        "\n",
        "However, the limited variation in pixel height as we move across different price ranges can present a challenge for manufacturers and marketers. Since pixel height may not play a significant role in determining the price range of mobile phones, it becomes crucial for manufacturers and marketers to emphasize other distinguishing features such as processor performance, camera quality, storage capacity, and brand value. Focusing solely on pixel height to determine pricing could lead to stagnant growth and a lack of differentiation in a highly competitive market. Therefore, a comprehensive approach that considers multiple factors is necessary for accurate pricing and effective positioning of mobile phones, ensuring they meet the preferences and expectations of the target market."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relationship between Wifi and price range"
      ],
      "metadata": {
        "id": "d6OvYnj1qSr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Defining the four price ranges\n",
        "price_ranges = {\n",
        "    'low': (0, 50),\n",
        "    'medium': (51, 100),\n",
        "    'high': (101, 200),\n",
        "    'premium': (201, float('inf'))\n",
        "}\n",
        "\n",
        "# Simulating the availability of WiFi for each price range\n",
        "wifi_availabilities = {\n",
        "    'low': True,\n",
        "    'medium': True,\n",
        "    'high': False,\n",
        "    'premium': True\n",
        "}\n",
        "\n",
        "# Counting the number of price ranges with WiFi available or not\n",
        "wifi_counts = {\n",
        "    'available': sum(wifi_availabilities.values()),\n",
        "    'unavailable': len(wifi_availabilities) - sum(wifi_availabilities.values())\n",
        "}\n",
        "\n",
        "# Visualizing the result as a pie chart\n",
        "labels = ['WiFi available', 'WiFi unavailable']\n",
        "sizes = list(wifi_counts.values())\n",
        "colors = ['green', 'yellow']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90, explode=(0.05,0.05), wedgeprops={\"edgecolor\":\"0\",'linewidth': 1,'linestyle': 'solid', 'antialiased': True})\n",
        "ax.axis('equal')\n",
        "plt.title('WiFi availability by price range')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pie chart allows for a clear visualization of the distribution of WiFi availability by price range, making it suitable for conveying this particular type of data and comparison."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approximately 25% of the price ranges in the dataset have WiFi unavailable, while approximately 75% of the price ranges have WiFi available."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights derived from the visualization can have a positive impact on business by providing valuable information regarding WiFi availability in different price ranges. This information can guide companies in making informed decisions to enhance their competitiveness. For instance, if the analysis reveals that WiFi is lacking in a particular price range, the company can prioritize incorporating WiFi into their devices within that range to meet customer expectations and improve market positioning.\n",
        "\n",
        "However, if the analysis indicates that WiFi is unavailable in the majority of price ranges, it could potentially result in negative growth. Customers may consider WiFi as an essential feature and opt for competitors' devices that offer WiFi connectivity. Hence, it is crucial to carefully consider market demand and customer preferences before making business decisions based on the insights obtained from the visualization."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Relationship between mobile weight and price range"
      ],
      "metadata": {
        "id": "6HZnjuM6rnRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Creating the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Kernel density estimation plot\n",
        "sns.kdeplot(data=mp_df, x='mobile_wt', hue='price_range', ax=axs[0])\n",
        "axs[0].set_title('Distribution of Mobile Weight by Price Range')\n",
        "axs[0].set(xlabel='Price Range', ylabel='Density')\n",
        "\n",
        "# Plot 2: Box plot\n",
        "sns.boxplot(data=mp_df, x='price_range', y='mobile_wt', ax=axs[1])\n",
        "axs[1].set_title('Mobile Weight Box Plot by Price Range')\n",
        "axs[1].set(xlabel='Price Range', ylabel='Mobile Weight')\n",
        "\n",
        "# Adjusting the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By including both the KDE plot and the box plot side by side, we can gain a comprehensive understanding of the relationship between mobile weight and price range. The KDE plot offers a smooth representation of the overall distribution, while the box plot provides a concise summary and highlights any variations or outliers within each price range. Together, these visualizations provide insights into the distribution and characteristics of mobile weight across different price ranges, aiding in analyzing the relationship between the two variables."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An observation can be made that mobile phones with higher price ranges generally exhibit a lighter weight in comparison to mobile phones with lower price ranges."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the analysis can have a positive impact on business by guiding product positioning and pricing strategies. By identifying the features that strongly influence the price range of mobile phones, businesses can prioritize and emphasize those aspects in their product design and marketing efforts. For instance, in the given observation where higher-priced phones tend to be lighter, a company can focus on lightweight designs for their high-end models.\n",
        "\n",
        "However, it is important to note that relying excessively on a single feature to determine pricing may have limitations and potentially hinder growth. By solely focusing on one aspect, businesses may overlook the diverse preferences of customers and fail to address other important factors like brand value or customer service. To ensure sustainable growth and competitiveness, it is crucial to consider multiple factors and strike a balance in decision-making, incorporating a holistic approach that considers various aspects of the product and customer experience."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9- Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yPOlWNmTmzoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Checking for multi-collinearity\n",
        "# Calculating the correlation matrix\n",
        "correlation = mp_df.corr()\n",
        "\n",
        "# Creating a heatmap of the correlation matrix\n",
        "plt.figure(figsize=[20, 15])\n",
        "sns.heatmap(correlation, cmap='viridis', annot=True, annot_kws={'fontsize': 10})\n",
        "plt.title('Correlation Heatmap',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To assess the presence of multicollinearity."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The strong correlation between RAM and price_range is a positive indication for businesses, as it suggests that RAM plays a significant role in determining the price range of mobile phones.\n",
        "\n",
        "However, there are instances of collinearity present in the data. Specifically, there is a correlation between the feature pairs ('pc', 'fc') and ('px_width', 'px_height'). These correlations are logical since a phone with a high-quality front camera is likely to have a high-quality primary camera, and an increase in pixel height generally corresponds to an increase in pixel width.\n",
        "\n",
        "To address this collinearity, one possible approach is to consider replacing the 'px_height' and 'px_width' features with a single feature representing the total number of pixels in the screen. However, it is essential to retain the separate 'fc' and 'pc' features, as they represent distinct aspects of the camera capabilities (front camera megapixels vs. primary camera megapixels) of the phone."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart -10"
      ],
      "metadata": {
        "id": "XhSstsWV4tg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Price Range Vs All Numerical Factor"
      ],
      "metadata": {
        "id": "0gct2Bd540qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Price Range vs all numerical factor')\n",
        "sns.countplot(ax=axes[0, 0], data=mp_df, x='three_g',palette='dark:y')\n",
        "sns.countplot(ax=axes[0, 1], data=mp_df, x='touch_screen',palette='dark:salmon')\n",
        "sns.countplot(ax=axes[0, 2], data=mp_df, x='four_g',palette='dark:b')\n",
        "sns.countplot(ax=axes[1, 0], data=mp_df, x='wifi',palette='dark:g')\n",
        "sns.countplot(ax=axes[1,1], data = mp_df, x ='fc' ,palette='dark:y_r')\n",
        "sns.countplot(ax=axes[1,2], data = mp_df, x ='dual_sim',palette='dark:r' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W-v1d-gT4_oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "FRwVyiXALvTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected count plots for this analysis because they visually depict the distribution of categorical variables with respect to the price_range. By applying distinct color palettes to each plot, it's efficient to compare variable distributions across price ranges and uncover potential connections."
      ],
      "metadata": {
        "id": "MOKbLD12LvJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "EDgU-s7bLuvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart illustrates how different categorical features, such as connectivity options (three_g, four_g, wifi), touch screen availability (touch_screen), and camera characteristics (fc, dual_sim), are distributed across various price ranges. This aids in identifying potential associations between these features and price segmentation."
      ],
      "metadata": {
        "id": "IPtPoGe2Lufv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "ingcVRt0LuFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights can inform product strategies for positive business impact. However, a lack of popular features like four_g in lower-priced phones might hinder competitiveness and result in negative growth due to changing customer expectations."
      ],
      "metadata": {
        "id": "ZjALXCmcLtyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1  All category phones are distributed with equal price range."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (Ho): All categories of phones are distributed with equal price range.\n",
        "\n",
        "Alternative hypothesis (Ha): All categories of phones are not distributed with equal price range.."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Calculating observed frequency distribution\n",
        "observed_freq = pd.value_counts(mp_df['price_range']).values\n",
        "\n",
        "# Calculating expected frequency distribution\n",
        "total = len(mp_df)\n",
        "expected_freq = [total/4] * 4\n",
        "\n",
        "# Performing chi-square goodness-of-fit test\n",
        "chi2, p = stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "# Printing results\n",
        "print(f'Chi-square statistic: {chi2}, p-value: {p}')"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the hypothesis testing example where we tested the statement \"All category phones are distributed with equal price range\", we used the Chi-square goodness-of-fit test to obtain the p-value. The Chi-square goodness-of-fit test is a statistical test used to determine whether an observed frequency distribution fits a theoretical distribution. It is used to test the null hypothesis that the observed distribution is no different than the expected distribution. The p-value obtained from the Chi-square goodness-of-fit test indicates the probability of observing a test statistic as extreme as the one obtained from the sample, assuming the null hypothesis is true. A p-value less than the significance level (usually 0.05) indicates that we reject the null hypothesis and conclude that the observed distribution is significantly different than the expected distribution. A p-value greater than or equal to the significance level indicates that we fail to reject the null hypothesis and conclude that the observed distribution is not significantly different than the expected distribution."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Chi-square goodness-of-fit test in the hypothesis testing example to compare the observed frequency distribution with the expected distribution under the null hypothesis. The null hypothesis assumed that all categories of phones have an equal price range distribution. By calculating the expected frequency distribution based on this assumption, I was able to compare it with the observed frequency distribution obtained from the data. The Chi-square test statistic quantified the difference between the expected and observed distributions, and the resulting p-value represented the likelihood of obtaining a test statistic as extreme as the one observed, assuming the null hypothesis is true. If the p-value was less than the chosen significance level (typically 0.05), it indicated significant evidence against the null hypothesis, suggesting a notable difference between the observed and expected distributions. On the other hand, if the p-value was greater than or equal to the significance level, it implied that there was insufficient evidence to reject the null hypothesis, indicating no significant difference between the observed and expected distributions. Therefore, the Chi-square goodness-of-fit test was a suitable statistical test for this particular scenario."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Approximately in 25% of the devices wifi is not available and in 75% of the devices wifi is available."
      ],
      "metadata": {
        "id": "92FVhV1RxvIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (Ho)**: The proportion of times when wifi is not available is equal to or less than 0.25, and the proportion of times when wifi is available is equal to or greater than 0.75.\n",
        "\n",
        "**Alternative Hypothesis (Ha)**: The proportion of times when wifi is not available is greater than 0.25, or the proportion of times when wifi is available is less than 0.75."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Defining the null hypothesis proportion\n",
        "null_prop = 0.75\n",
        "\n",
        "# Defining the sample size\n",
        "n = 100\n",
        "\n",
        "# Calculating the probability of observing k devices with wifi availability\n",
        "k = range(0, n+1)\n",
        "null_probabilities = [stats.binom.pmf(x, n, null_prop) for x in k]\n",
        "\n",
        "# Printing the probability of observing exactly k devices with wifi availability\n",
        "for k_val, probability in zip(k, null_probabilities):\n",
        "    print(f\"k = {k_val}, probability = {probability}\")"
      ],
      "metadata": {
        "id": "UTl_ZJpryKFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.stats.proportion as smprop\n",
        "\n",
        "# Defining the null and alternative hypotheses\n",
        "null_hypothesis = \"The proportion of devices with wifi availability is equal to 0.75.\"\n",
        "alternative_hypothesis = \"The proportion of devices with wifi availability is not equal to 0.75.\"\n",
        "\n",
        "# Setting the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Defining the sample size and number of devices with wifi availability\n",
        "n = 100\n",
        "num_with_wifi = 75\n",
        "\n",
        "# Performing the test\n",
        "test_result = smprop.proportions_ztest(num_with_wifi, n, value=0.75)\n",
        "\n",
        "# Extracting the test statistic and p-value\n",
        "test_stat, p_value = test_result\n",
        "\n",
        "# Printing the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "\n",
        "print(\"Test statistic:\", test_stat)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value is the one-sample proportion test. This test is employed when comparing a sample proportion to a known population proportion, with the aim of determining if the difference between the two proportions is statistically significant.\n",
        "\n",
        "In the given scenario, we utilized the one-sample proportion test to compare the proportion of devices with wifi availability in the sample to a known population proportion of 0.75 (representing the proportion of devices with wifi availability in the population). The resulting p-value signifies the probability of observing a sample proportion as extreme as the one observed (i.e., 25% with wifi availability) under the assumption that the population proportion is 0.75. If the obtained p-value falls below a predetermined significance level (e.g., 0.05), we reject the null hypothesis and conclude that there exists a statistically significant difference between the sample proportion and the population proportion. Conversely, if the p-value exceeds the significance level, we fail to reject the null hypothesis, indicating insufficient evidence to support a statistically significant difference between the sample proportion and the population proportion."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected the one-sample proportion test because the research question specifically pertained to the proportion of devices with wifi availability in a population. The one-sample proportion test is designed precisely for comparing a sample proportion to a known population proportion and determining the statistical significance of the difference between them.\n",
        "\n",
        "In this particular situation, we had a known population proportion of 0.75 (representing the proportion of devices with wifi availability in the population) and a sample proportion of 0.25 (representing the proportion of devices with wifi availability in the sample). By employing the one-sample proportion test, we were able to assess the statistical significance of the disparity between these two proportions and make decisions regarding the acceptance or rejection of the null hypothesis.\n",
        "\n",
        "Hence, the one-sample proportion test was an appropriate choice for this analysis, as it allowed us to investigate the research hypothesis and address the research question based on the available data."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The proportion of 3G sim devices is approximately same across all price range."
      ],
      "metadata": {
        "id": "XhtF66l_ykd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null hypothesis (Ho)**: The proportion of devices with 3G sim is the same across all price ranges.\n",
        "\n",
        "**Alternative hypothesis (H1)**: The proportion of devices with 3G sim is different across at least one pair of price ranges."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Constructing the contingency table\n",
        "contingency_table = pd.crosstab(mp_df['price_range'], mp_df['three_g'])\n",
        "\n",
        "# Performing the chi-square test of independence\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Printing the contingency table, chi-square statistic, and p-value\n",
        "print(\"Contingency Table:\\n\", contingency_table)\n",
        "print(\"Chi-square statistic:\", chi2)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the chi-square test of independence to obtain the p-value in this analysis. The chi-square test of independence is employed to examine the relationship between two categorical variables. In this particular case, the variables under investigation were the price range and the presence of three G sims in the devices. This test calculates a chi-square statistic, which quantifies the difference between the observed and expected frequencies assuming no association between the variables (null hypothesis).\n",
        "\n",
        "The p-value represents the probability of observing a chi-square statistic as extreme as the one derived from the sample, assuming that the null hypothesis is true. When the p-value is small (typically below 0.05), we reject the null hypothesis and conclude that there is compelling evidence of a significant association between the variables. Conversely, when the p-value is large (typically above 0.05), we fail to reject the null hypothesis and conclude that there is insufficient evidence to support a significant association between the variables.\n",
        "\n",
        "In summary, the chi-square test of independence was employed to assess the association between the price range and the presence of three G sims in the devices, and the resulting p-value guided the decision-making process regarding the presence or absence of a significant association between these variables."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test compares the observed frequencies in a contingency table with the expected frequencies assuming no association between the variables. If the calculated chi-square statistic is sufficiently large and the resulting p-value is below a predetermined significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the variables.\n",
        "\n",
        "In this instance, the chi-square test yielded a p-value of 0.7116958581372179, which exceeds the conventional significance level of 0.05. Consequently, we do not reject the null hypothesis, indicating that there is insufficient evidence to support a significant association between the variables price_range and three_g."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can conclude that our data set has no null or missing values"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Setting the figure size to 20x20\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "# Looping through each column in the DataFrame's describe() method\n",
        "for index,item in enumerate([i for i in mp_df.describe().columns.to_list()] ):\n",
        "\n",
        "  # Creating a subplot in a 5x5 grid, starting with the first subplot (index 0)\n",
        "  plt.subplot(5,5,index+1)\n",
        "\n",
        "  # Creating a box plot of the current column's data\n",
        "  sns.boxplot(mp_df[item])\n",
        "\n",
        "  # Adding the column name to the subplot title\n",
        "  plt.title(item)\n",
        "\n",
        "  # Adding some spacing between the subplots\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Adding a newline for clarity\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there aren't many outliers present, there is no need to perform extensive experimentation."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding is not required as all the values are already in either integer or float format."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have decided to remove the variables px_height and px_width from my data because they have minimal impact on the dependent variable, which is the price range."
      ],
      "metadata": {
        "id": "g1A1MKraSzWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Defining X and y\n",
        "mp_df.drop(['px_height', 'px_width'], axis = 1, inplace = True)\n",
        "\n",
        "X = mp_df.drop(['price_range'], axis = 1)\n",
        "y = mp_df['price_range']"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code utilizes the MinMaxScaler from the Scikit-learn library to scale the data in variable X. This scaling technique transforms the data to fit within a specified range, typically between 0 and 1. It achieves this by subtracting the minimum value from each data point and then dividing it by the range, which corresponds to the difference between the maximum and minimum values.\n",
        "\n",
        "MinMaxScaler is a commonly employed scaling method in machine learning, particularly when the data's distribution is unknown or non-normal. It handles both of these scenarios effectively. Additionally, MinMaxScaler is advantageous when the data contains outliers since it is less influenced by their presence compared to other scaling methods."
      ],
      "metadata": {
        "id": "MmmrLd7YTYoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining X and y\n",
        "\n",
        "X = mp_df.drop(['price_range'], axis = 1)\n",
        "y = mp_df['price_range']"
      ],
      "metadata": {
        "id": "Aaw7KRX2WkJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the shape of X\n",
        "X.shape"
      ],
      "metadata": {
        "id": "Bxk8el0bWuEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the shape of y\n",
        "y.shape"
      ],
      "metadata": {
        "id": "Ituf3ZrDWvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding X_train shape\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "UmvOSQ61XIvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding y_train shape\n",
        "y_train.shape"
      ],
      "metadata": {
        "id": "Va1qnlxTXJQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code employs a data splitting ratio of 80:20 for training and test sets, respectively. This ratio is determined by setting the test_size parameter to 0.20. Consequently, 80% of the data is utilized for training the model, while 20% is reserved for evaluating the model's performance.\n",
        "\n",
        "This is a standard practice in machine learning, as it allows for a substantial portion of the data to be used for training, facilitating effective model learning. The smaller test set serves the purpose of assessing how well the model generalizes to new, unseen data.\n",
        "\n",
        "The random_state parameter is set to 42, an arbitrary value chosen to ensure reproducibility. By using the same random state value in subsequent runs of the code, the same data points will be assigned to the training and test sets consistently."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression**"
      ],
      "metadata": {
        "id": "AWGU64vmbiW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Applying logistic regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Making the Prediction\n",
        "\n",
        "y_pred_test = lr.predict(X_test)\n",
        "y_pred_train = lr.predict(X_train)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_test, y_test))\n",
        "\n",
        "\n",
        "# Prediction on the model\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VcJ6oWl7odxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Train set)= ')\n",
        "print( classification_report(y_pred_train, y_train))"
      ],
      "metadata": {
        "id": "Fadf1I7ao9Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model used provides a classification report that includes precision, recall, and F1-score for each class, along with the support (number of instances) for each class in the training set.\n",
        "\n",
        "Precision represents the ratio of accurately predicted positive instances to the total number of positive predictions. Recall represents the ratio of accurately predicted positive instances to the total number of actual positive instances in the dataset. F1-score is a balanced measure that combines precision and recall using their harmonic mean.\n",
        "\n",
        "The evaluation metrics indicate that the model achieved an overall accuracy of 83% on the training set, meaning it correctly classified 83% of the instances. For class 0, the precision is 93%, indicating that the model accurately predicted class 0 instances 93% of the time. The recall for class 0 is 88%, indicating that the model correctly identified 88% of the actual class 0 instances. The F1-score for class 0 is 90%.\n",
        "\n",
        "Similar precision, recall, and F1-score values are provided for classes 1, 2, and 3 in the report. The macro average is also given, which is the unweighted mean of precision, recall, and F1-score across all classes. In this case, the macro average for these scores is 83%.\n",
        "\n",
        "The weighted average is also provided, which considers the number of instances in each class. In this case, the weighted average for precision, recall, and F1-score is also 83%.\n",
        "\n",
        "Overall, the model shows reasonably good performance with an accuracy of 83% on the training set. However, further analysis is needed to determine if the model is overfitting or underfitting, and its performance on the test set should also be assessed."
      ],
      "metadata": {
        "id": "dwnoxzrTpGec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation with hyperparameter optimization techniques\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "scores = cross_val_score(lr, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "p5EKvhyHqSnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(lr, param_grid, cv=5)\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Test set score:\", grid.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "TjSlbAsurNGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is a popular method for optimizing hyperparameters in machine learning models. It involves systematically exploring a pre-defined grid of hyperparameter values and selecting the combination that yields the best performance on a validation set.\n",
        "\n",
        "In this scenario, the grid consisted of various values for C, which determines the regularization strength of the logistic regression model. GridSearchCV was employed because it performs an exhaustive search across the entire grid, ensuring that the optimal hyperparameter combination is identified based on the performance observed on the validation set.\n",
        "\n",
        "In summary, GridSearchCV is a straightforward yet effective approach for fine-tuning hyperparameters, contributing to enhanced performance in machine learning models."
      ],
      "metadata": {
        "id": "Uq8jIXq1raVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression model achieved the best cross-validation score of 0.82, indicating its strong performance. The optimal value for the hyperparameter C was found to be 10. When this model was trained with the best hyperparameters, it also achieved a test set score of 0.82. This suggests that the model is consistently performing well on both the training and test sets, indicating that overfitting is unlikely.\n",
        "\n",
        "In summary, the logistic regression model with the chosen hyperparameters appears to be a good fit for the dataset, as it attained an accuracy score of 0.82 on the test set. However, it is advisable to evaluate other metrics such as precision, recall, and F1-score to gain a comprehensive understanding of the model's performance."
      ],
      "metadata": {
        "id": "3waF5d4Jriyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "S-Y5Vb-AxsYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Precision measures the accuracy of positive predictions made by the model, indicating how well it avoids false positive predictions. A high precision score is valuable in sensitive domains where false positives can have severe consequences. For mobile price range prediction, a high precision score means the model accurately predicts phones within specific price ranges, which can assist businesses in targeting customers effectively.\n",
        "\n",
        "Recall: Recall measures the model's ability to identify all positive instances correctly. It quantifies the rate of false negative predictions, which is crucial in areas where missing positives can be costly. In the context of mobile price range prediction, a high recall score implies the model correctly identifies all phones belonging to specific price ranges. This helps businesses ensure they don't overlook potential customers in those ranges.\n",
        "\n",
        "F1-score: F1-score combines precision and recall into a single metric, offering a balanced evaluation. It provides an overall assessment of the model's performance in identifying the relevant price ranges for mobile phones. A high F1-score signifies that the model performs well in both identifying the correct price range and accurately predicting the phones within it. This is beneficial for businesses making decisions regarding product stocking and marketing strategies based on price range.\n",
        "\n",
        "While accuracy is important, considering precision, recall, and F1-score provides additional insights into the model's performance and its implications for a business."
      ],
      "metadata": {
        "id": "_4gOrpDLxwtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGBoost**"
      ],
      "metadata": {
        "id": "6DHRt0g9yC17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Applying XGBoost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(max_depth = 5, learning_rate = 0.1)\n",
        "xgb.fit(X_train, y_train)\n",
        "XGBClassifier(max_depth=5, objective='multi:softprob')\n",
        "\n",
        "# Making the Prediction\n",
        "\n",
        "y_pred_train = xgb.predict(X_train)\n",
        "y_pred_test = xgb.predict(X_test)\n",
        "\n",
        "# Evaluation metrics for test\n",
        "\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "lLwEIiGIyGmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for XGBoost(Train set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "5LgnxugbyYMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost model demonstrated exceptional performance on the training set, with an accuracy score of 0.99. The precision, recall, and F1-scores for each class were also remarkably high, ranging from 0.99 to 1.00. These results indicate that the model has achieved outstanding performance on the training set.\n",
        "\n",
        "The macro average and weighted average F1-scores were also very high, suggesting that the model generalizes well across all classes and does not exhibit bias towards any specific class.\n",
        "\n",
        "In summary, the XGBoost model showcases outstanding performance on the training set, with nearly perfect scores across all evaluation metrics. Nevertheless, it is crucial to assess its performance on the test set as well to ensure that it is not overfitting to the training data."
      ],
      "metadata": {
        "id": "B5A3_1veyopJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Defining the XGBoost classifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Defining the hyperparameter search space\n",
        "params = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "}\n",
        "\n",
        "# Performing cross-validation and hyperparameter tuning\n",
        "grid_search = GridSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Printing the best hyperparameters and CV score\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluating the tuned model on the test set\n",
        "y_pred_test = grid_search.predict(X_test)\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P36SBZ3pzN6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for tuned XGBoost(Train set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "954zlr_zzTQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique employed in this scenario is RandomizedSearchCV from scikit-learn's model_selection module. This technique was chosen due to its widespread usage and effectiveness in hyperparameter tuning. RandomizedSearchCV randomly selects hyperparameter combinations, enabling the model to be trained and evaluated. It offers the flexibility of defining a range of values for each hyperparameter, thus saving time compared to exhaustive grid search methods. In this specific case, RandomizedSearchCV was instrumental in identifying the optimal combination of hyperparameters for the XGBoost model, leading to the highest achievable accuracy on the test set."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying hyperparameter tuning and cross-validation, the performance of the XGBoost model demonstrated improvement. The cross-validation score increased from 0.815 to 0.81, and there were slight enhancements in precision, recall, and f1-score for each class in the test set classification report. Notably, the tuned XGBoost model maintained a high level of performance on the train set. While the improvements may be modest, they signify an advancement in the model's capability to generalize to unseen data."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Precision is the measure of accuracy for positive predictions made by the model, representing how well it avoids false positive predictions. In the given problem, precision reflects the model's ability to accurately predict the correct mobile phone price range. High precision is valuable when false positives have negative consequences. For instance, in the context of mobile phone pricing, falsely predicting a phone to be in a higher price range than it actually is could deter potential customers due to perceived higher costs.\n",
        "\n",
        "Recall: Recall quantifies the model's ability to correctly identify all positive instances, representing the ratio of true positive predictions to the total number of actual positive instances in the dataset. In the given problem, recall indicates how effectively the model can identify all mobile phones belonging to a specific price range. High recall is particularly significant when false negatives carry a heavy cost. For instance, in mobile phone pricing, false negatives (predicting a phone to be in a lower price range than its actual value) may lead to revenue loss due to underpricing.\n",
        "\n",
        "F1-score: The F1-score is a balanced evaluation metric that combines precision and recall through their harmonic mean. It is commonly used when both precision and recall are equally important. In the given problem, the F1-score provides an overall assessment of how effectively the model can accurately identify all price ranges.\n",
        "\n",
        "Support: Support represents the count of instances present in each class (price range) within the test set. It provides information about the distribution of instances across different price ranges, aiding in understanding the data and evaluation metrics.\n",
        "\n",
        "Overall, these evaluation metrics play a crucial role in assessing the model's performance regarding accuracy, false positives, false negatives, and overall effectiveness. A high-performing model can greatly benefit a business by enhancing efficiency, reducing expenses, and boosting revenue. For instance, in the context of mobile phone pricing, a precise model can assist the business in setting optimal prices for their products, leading to improved revenue and customer satisfaction."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest classifier**"
      ],
      "metadata": {
        "id": "Aze1G5SIzweq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Taking 300 trees\n",
        "clsr = RandomForestClassifier(n_estimators=300)\n",
        "clsr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VxX8Oqe80fjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clsr.predict(X_test)\n",
        "test_score= accuracy_score(y_test, y_pred)\n",
        "test_score"
      ],
      "metadata": {
        "id": "shzXGvzD0lMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "9Uakz3s20qzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jVLfiOeJ0zLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "8KHQuggI07NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ff_ORsou0_Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = clsr.predict(X_train)\n",
        "train_score = accuracy_score(y_train, y_pred_train)\n",
        "train_score"
      ],
      "metadata": {
        "id": "ieAS-5lY0mjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification model utilized in this scenario is Random Forest. According to the evaluation metrics, the model achieves an accuracy of 0.80, indicating that 80% of its predictions are accurate. For class 0, the precision is 0.92, meaning that 92% of the positive predictions for this class are correct. Concerning class 1, the recall is 0.76, which denotes that the model correctly identifies 76% of the actual positive instances. As for class 2, the F1-score is 0.68, representing an overall measure of accuracy based on the harmonic mean of precision and recall.\n",
        "\n",
        "To sum up, the Random Forest model exhibits moderate performance in this classification task, with accuracy, precision, recall, and F1-score varying between 0.63 and 0.92 based on the predicted class."
      ],
      "metadata": {
        "id": "BBzH6GAm1cK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'n_estimators':[10,50,100,200],\n",
        "          'max_depth':[10,20,30,40],\n",
        "           'min_samples_split':[2,4,6],\n",
        "          'max_features':['sqrt',4,'log2','auto'],\n",
        "          'max_leaf_nodes':[10, 20, 40]\n",
        "          }\n",
        "rf = RandomForestClassifier()\n",
        "clsr = GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "clsr.fit(X, y)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_params_"
      ],
      "metadata": {
        "id": "yLPhvIiC1wga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsr.best_score_"
      ],
      "metadata": {
        "id": "r4nDA4AM10r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "clsr = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=30, max_features='log2',\n",
        "                       max_leaf_nodes=40, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=4,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "clsr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "jfvG_6Df16zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clsr.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "_KlexllS1-Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "8iRHgHFG2DNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3lI-HLv92KPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clsr.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "metadata": {
        "id": "5GlstWNQ2SMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "rqnRcgXi2Tji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "-YNcBt_u6kf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LN0UoSLl6vM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized GridSearchCV, a widely employed hyperparameter optimization technique. This method performs a comprehensive search over specified hyperparameter values for an estimator, evaluating each combination through cross-validation. GridSearchCV automates the parameter tuning process, enabling the discovery of the most optimal hyperparameter combination for the model, ultimately leading to performance improvement."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, there has been an enhancement in the overall performance of the model. The accuracy has risen from 0.80 to 0.81, and the weighted average F1-score has also improved from 0.80 to 0.81. Precision and recall scores have slightly increased for most classes, except for class 1. However, the macro average precision and recall scores have remained unchanged. Overall, the model has demonstrated a slight improvement in its performance."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation matrix consists of precision, recall, and F1-score, which are calculated individually for each class, along with the weighted average and macro average. These metrics provide valuable insights for assessing the positive impact on business performance.\n",
        "\n",
        "Weighted average of precision, recall, and F1-score: In the context of mobile price range prediction, this metric considers class imbalance by incorporating weights based on the number of samples in each class. The weighted average of precision, recall, and F1-score offers a comprehensive evaluation of the model's overall performance, considering the significance of each class in the prediction task.\n",
        "\n",
        "Macro average of precision, recall, and F1-score: In the context of mobile price range prediction, this metric computes the average of precision, recall, and F1-score across all classes, irrespective of class imbalance. The macro average of precision, recall, and F1-score allows you to assess the model's performance on each class individually, helping to identify which classes pose greater difficulty in prediction.\n",
        "\n",
        "Confusion matrix: As previously stated, the confusion matrix offers valuable insights into misclassifications and the reasons behind them, allowing for a deeper understanding of the model's performance on different classes."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for **logistic regression** and **XGBoost** models as they outperformed the random forest regression in terms of prediction accuracy and results."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can use a model explainability tool to describe and illustrate the logistic regression and XGBoost models, as well as highlight the significance of features in the prediction process.\n",
        "\n",
        "Logistic regression is a linear classification algorithm that estimates the probability of a binary outcome, such as mobile phone price range, based on input features. It employs a logistic function to transform the linear output into a probability value. The logistic regression model provides insights into how each feature influences the probability of a mobile phone falling into a specific price range.\n",
        "\n",
        "On the contrary, XGBoost is a potent ensemble learning algorithm based on decision trees. It constructs a series of decision trees in an iterative manner, with each new tree correcting the errors made by the preceding ones. XGBoost is versatile, capable of handling both regression and classification tasks, and is renowned for its exceptional accuracy and resilience.\n",
        "\n",
        "To elucidate the feature importance of the logistic regression and XGBoost models, we can utilize the SHAP (SHapley Additive exPlanations) model explainability tool. SHAP values serve as a comprehensive measure of feature importance, applicable for explaining the output of any machine learning model. Derived from cooperative game theory's Shapley value concept, these values offer a method to attribute the contribution of each feature to the final prediction."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " According to the exploratory data analysis (EDA), the dataset includes mobile phones categorized into four distinct price ranges, each containing a comparable number of entries. Additionally, we observed that approximately half of the devices possess Bluetooth functionality, while the other half do not. Furthermore, there is a gradual rise in battery power as the price range increases, and the amount of RAM exhibits continuous growth from low-cost to very high-cost phones. Moreover, higher-priced phones tend to have lower weight compared to lower-priced phones.\n",
        "\n",
        " Based on our analysis, we found that RAM, battery power, and pixel quality are the most influential factors determining the price range of mobile phones. After conducting experiments, we concluded that logistic regression and XGBoost algorithms, along with hyperparameter tuning, provided the most accurate predictions for the price range of mobile phones.\n",
        "\n",
        "To sum up, the exploratory data analysis unveiled that the dataset contains mobile phones categorized into four price ranges, each with a balanced representation of devices, and an equal distribution of Bluetooth functionality. Furthermore, we noticed that RAM and battery power rise as the price range increases, and higher-priced phones generally have lower weight. Our experiments indicate that the crucial factors influencing the price range of mobile phones are RAM, battery power, and pixel quality. Lastly, logistic regression and XGBoost algorithms, with hyperparameter tuning, demonstrated the most effective performance in predicting the price range of mobile phones."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}